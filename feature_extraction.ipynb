{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Verify the gradient derivation of linear masked autoencoder.\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear auto-encoder model\n",
    "class LAE(nn.Module):\n",
    "    def __init__(self, n, p):\n",
    "        super(LAE, self).__init__()\n",
    "        self.n = n\n",
    "        self.p = p\n",
    "        self.w1 = nn.Linear(n, p, bias=False)\n",
    "        self.w2 = nn.Linear(p, n, bias=False)\n",
    "\n",
    "    def forward(self, y):\n",
    "        y = self.w1(y)\n",
    "        y = self.w2(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Masked lienar auto-encoder model\n",
    "# Define different types of masks\n",
    "def mask_basic(prob, sample_num, feature_num):\n",
    "    return torch.zeros(sample_num, feature_num).bernoulli_(prob)\n",
    "\n",
    "def mask_dropping_probs(prob_list: torch.Tensor, sample_num, feature_num):\n",
    "    return torch.zeros(sample_num, feature_num).bernoulli_(prob_list)\n",
    "\n",
    "def mask_patches(prob, patch_size, sample_num, sample_dim):\n",
    "    patch_size = torch.tensor(patch_size)\n",
    "    sample_dim = torch.tensor(sample_dim)\n",
    "    feature_num = sample_dim[0]*sample_dim[1]\n",
    "    div_check = sample_dim % patch_size == torch.zeros(2)\n",
    "    if torch.all(div_check):\n",
    "        pix_num = torch.div(sample_dim, patch_size, rounding_mode='floor')\n",
    "        mat_patches = torch.zeros(sample_num, *pix_num).bernoulli_(prob)\n",
    "        mat_patches = torch.repeat_interleave(mat_patches, patch_size[1], dim=2)\n",
    "        return mat_patches.repeat_interleave(patch_size[0], dim=1).view(sample_num, feature_num)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Both height ({sample_dim[0]}) and width ({sample_dim[1]}) should be divisible by patch_size ({patch_size}).\")\n",
    "\n",
    "\n",
    "# Masked autoencoder (linear)\n",
    "class M_LAE(nn.Module):\n",
    "    def __init__(self, prob, sample_dim, reduction_dim, type='basic', patch_size=None):\n",
    "        super(M_LAE, self).__init__()\n",
    "        self.prob = prob\n",
    "        self.sample_dim = sample_dim\n",
    "        self.H, self.W = sample_dim\n",
    "        self.n = self.H * self.W\n",
    "        self.p = reduction_dim\n",
    "        if type not in ['basic', 'probs', 'patches']:\n",
    "            raise NotImplementedError(\"Could only implement 'basic', 'probs' and 'patches' type of masking.\")\n",
    "        else:\n",
    "            self.masking_type = type\n",
    "        if patch_size is not None:\n",
    "            self.patch_size = patch_size\n",
    "        w1 = nn.Linear(self.n, self.p, bias=False)\n",
    "        w2 = nn.Linear(self.p, self.n, bias=False)\n",
    "        self.body = nn.Sequential(*[w1, w2])\n",
    "    \n",
    "    def forward(self, X, mask=None):\n",
    "        m = X.shape[0]\n",
    "        if mask is None:\n",
    "            if self.masking_type == 'basic':\n",
    "                mask = mask_basic(self.prob, m, self.n)\n",
    "            elif self.masking_type == 'probs':\n",
    "                mask = mask_dropping_probs(self.prob, m, self.n)\n",
    "            elif self.masking_type == 'patches':\n",
    "                mask = mask_patches(self.prob, self.patch_size, m, self.sample_dim)\n",
    "        Y = mask * X\n",
    "        Y = self.body(Y)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(data_dict, model, criterion, optimizer, epochs=10, sample_average=20):\n",
    "    test_loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    test_inputs = data_dict['test_inputs']\n",
    "    test_targets = data_dict['test_targets']\n",
    "\n",
    "    for epoch in range(epochs+1):\n",
    "        loss_total = 0\n",
    "        optimizer.zero_grad()\n",
    "        for i in range(sample_average):\n",
    "            test_outputs = model(test_inputs)\n",
    "            loss = criterion(test_outputs, test_targets)\n",
    "            loss_total += loss\n",
    "        loss_total /= sample_average\n",
    "        loss_total.backward()\n",
    "        optimizer.step()\n",
    "        test_loss.append(loss_total.item())\n",
    "        if epoch % (epochs//10) == 0:\n",
    "            v_loss = test_loop(data_dict, model, criterion)\n",
    "            val_loss.append(v_loss)\n",
    "            print('epoch: ', epoch, ', test loss: ', loss.item(), ', val loss', v_loss)\n",
    "    return {'test_loss': test_loss, 'val_loss': val_loss}\n",
    "\n",
    "def test_loop(data_dict, model, criterion):\n",
    "    val_inputs = data_dict['val_inputs']\n",
    "    val_targets = data_dict['val_targets']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(val_inputs)\n",
    "        loss = criterion(val_outputs, val_targets)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "class FE_Net(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(FE_Net, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.theta = nn.Linear(in_dim, out_dim, bias=False)\n",
    "\n",
    "    def forward(self, W):\n",
    "        return self.theta(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num = 80\n",
    "val_num = 20\n",
    "H = 8\n",
    "W = 8\n",
    "sample_dim = torch.tensor([H, W])\n",
    "feature_num = H * W\n",
    "reduction_dim = 3 * feature_num // 4\n",
    "target_dim = feature_num // 2\n",
    "\n",
    "prob = 0.75\n",
    "prob_list = torch.rand(feature_num)*0.2 + 0.65\n",
    "patch_size = torch.div(sample_dim, 4, rounding_mode='floor')\n",
    "\n",
    "test_inputs = torch.rand(test_num, feature_num) * 2\n",
    "test_targets = torch.rand(test_num, target_dim)\n",
    "val_inputs = torch.rand(val_num, feature_num) * 2\n",
    "val_targets = torch.rand(val_num, target_dim)\n",
    "data_dict = {'test_inputs': test_inputs, 'test_targets': test_inputs,\n",
    "             'val_inputs': val_inputs, 'val_targets': val_inputs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get features from autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "fe_learning_rate = 0.00003\n",
    "epochs = 8000\n",
    "fe_epochs = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_LAE = LAE(feature_num, reduction_dim)\n",
    "\n",
    "params = list(net_LAE.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(params, lr=learning_rate)\n",
    "\n",
    "### TRAINING ###\n",
    "loss_LAE = train_loop(data_dict, net_LAE, criterion, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_LAE['test_loss'])\n",
    "plt.plot(range(0, epochs+1, epochs//10), loss_LAE['val_loss'])\n",
    "plt.legend(loss_LAE.keys())\n",
    "\n",
    "del loss_LAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "params_LAE = list(net_LAE.parameters())\n",
    "W1_LAE = params_LAE[0].clone().detach()\n",
    "fe_LAE_test_inputs = test_inputs @ W1_LAE.T\n",
    "fe_LAE_val_inputs = val_inputs @ W1_LAE.T\n",
    "\n",
    "fe_dict = {'test_inputs': fe_LAE_test_inputs, 'test_targets': test_targets,\n",
    "          'val_inputs': fe_LAE_val_inputs, 'val_targets': val_targets}\n",
    "\n",
    "net_LAE_fe = FE_Net(reduction_dim, target_dim)\n",
    "\n",
    "params = list(net_LAE_fe.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(params, lr=fe_learning_rate)\n",
    "\n",
    "### TRAINING ###\n",
    "loss_LAE_fe = train_loop(fe_dict, net_LAE_fe, criterion, optimizer, epochs=fe_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_LAE_fe['test_loss'])\n",
    "plt.plot(range(0, fe_epochs+1, fe_epochs//10), loss_LAE_fe['val_loss'])\n",
    "plt.legend(loss_LAE_fe.keys())\n",
    "\n",
    "net_LAE.cpu()\n",
    "del net_LAE\n",
    "\n",
    "net_LAE_fe.cpu()\n",
    "del net_LAE_fe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Masked linear autoencoder (basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_MLAE_basic = M_LAE(prob, sample_dim, reduction_dim)\n",
    "\n",
    "params = list(net_MLAE_basic.body.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(params, lr=learning_rate)\n",
    "\n",
    "### TRAINING ###\n",
    "loss_MLAE_basic = train_loop(data_dict, net_MLAE_basic, criterion, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_MLAE_basic['test_loss'])\n",
    "plt.plot(range(0, epochs+1, epochs//10), loss_MLAE_basic['val_loss'])\n",
    "plt.legend(loss_MLAE_basic.keys())\n",
    "\n",
    "del loss_MLAE_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "params_MLAE_basic = list(net_MLAE_basic.body.parameters())\n",
    "W1_MLAE_basic = params_MLAE_basic[0].clone().detach()\n",
    "fe_MLAE_basic_test_inputs = test_inputs @ W1_MLAE_basic.T\n",
    "fe_MLAE_basic_val_inputs = val_inputs @ W1_MLAE_basic.T\n",
    "\n",
    "fe_dict = {'test_inputs': fe_MLAE_basic_test_inputs, 'test_targets': test_targets,\n",
    "          'val_inputs': fe_MLAE_basic_val_inputs, 'val_targets': val_targets}\n",
    "\n",
    "net_MLAE_basic_fe = FE_Net(reduction_dim, target_dim)\n",
    "\n",
    "params = list(net_MLAE_basic_fe.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(params, lr=fe_learning_rate)\n",
    "\n",
    "### TRAINING ###\n",
    "loss_MLAE_basic_fe = train_loop(fe_dict, net_MLAE_basic_fe, criterion, optimizer, epochs=fe_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_MLAE_basic_fe['test_loss'])\n",
    "plt.plot(range(0, fe_epochs+1, fe_epochs//10), loss_MLAE_basic_fe['val_loss'])\n",
    "plt.legend(loss_MLAE_basic_fe.keys())\n",
    "\n",
    "net_MLAE_basic.cpu()\n",
    "del net_MLAE_basic\n",
    "\n",
    "net_MLAE_basic_fe.cpu()\n",
    "del net_MLAE_basic_fe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Masked linear autoencoder (probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_MLAE_probs = M_LAE(prob_list, sample_dim, reduction_dim, type='probs')\n",
    "\n",
    "params = list(net_MLAE_probs.body.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(params, lr=learning_rate)\n",
    "\n",
    "### TRAINING ###\n",
    "loss_MLAE_probs = train_loop(data_dict, net_MLAE_probs, criterion, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_MLAE_probs['test_loss'])\n",
    "plt.plot(range(0, epochs+1, epochs//10), loss_MLAE_probs['val_loss'])\n",
    "plt.legend(loss_MLAE_probs.keys())\n",
    "\n",
    "del loss_MLAE_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "params_MLAE_probs = list(net_MLAE_probs.body.parameters())\n",
    "W1_MLAE_probs = params_MLAE_probs[0].clone().detach()\n",
    "fe_MLAE_probs_test_inputs = test_inputs @ W1_MLAE_probs.T\n",
    "fe_MLAE_probs_val_inputs = val_inputs @ W1_MLAE_probs.T\n",
    "\n",
    "fe_dict = {'test_inputs': fe_MLAE_probs_test_inputs, 'test_targets': test_targets,\n",
    "          'val_inputs': fe_MLAE_probs_val_inputs, 'val_targets': val_targets}\n",
    "\n",
    "net_MLAE_probs_fe = FE_Net(reduction_dim, target_dim)\n",
    "\n",
    "params = list(net_MLAE_probs_fe.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(params, lr=fe_learning_rate)\n",
    "\n",
    "### TRAINING ###\n",
    "loss_MLAE_probs_fe = train_loop(fe_dict, net_MLAE_probs_fe, criterion, optimizer, epochs=fe_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_MLAE_probs_fe['test_loss'])\n",
    "plt.plot(range(0, fe_epochs+1, fe_epochs//10), loss_MLAE_probs_fe['val_loss'])\n",
    "plt.legend(loss_MLAE_probs_fe.keys())\n",
    "\n",
    "net_MLAE_probs.cpu()\n",
    "del net_MLAE_probs\n",
    "\n",
    "net_MLAE_probs_fe.cpu()\n",
    "del net_MLAE_probs_fe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Masked linear autoencoder (patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_MLAE_patches = M_LAE(prob, sample_dim, reduction_dim, type='patches', patch_size=patch_size)\n",
    "\n",
    "params = list(net_MLAE_patches.body.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(params, lr=learning_rate)\n",
    "\n",
    "### TRAINING ###\n",
    "loss_MLAE_patches = train_loop(data_dict, net_MLAE_patches, criterion, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_MLAE_patches['test_loss'])\n",
    "plt.plot(range(0, epochs+1, epochs//10), loss_MLAE_patches['val_loss'])\n",
    "plt.legend(loss_MLAE_patches.keys())\n",
    "\n",
    "del loss_MLAE_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "params_MLAE_patches = list(net_MLAE_patches.body.parameters())\n",
    "W1_MLAE_patches = params_MLAE_patches[0].clone().detach()\n",
    "fe_MLAE_patches_test_inputs = test_inputs @ W1_MLAE_patches.T\n",
    "fe_MLAE_patches_val_inputs = val_inputs @ W1_MLAE_patches.T\n",
    "\n",
    "fe_dict = {'test_inputs': fe_MLAE_patches_test_inputs, 'test_targets': test_targets,\n",
    "          'val_inputs': fe_MLAE_patches_val_inputs, 'val_targets': val_targets}\n",
    "\n",
    "net_MLAE_patches_fe = FE_Net(reduction_dim, target_dim)\n",
    "\n",
    "params = list(net_MLAE_patches_fe.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(params, lr=fe_learning_rate)\n",
    "\n",
    "### TRAINING ###\n",
    "loss_MLAE_patches_fe = train_loop(fe_dict, net_MLAE_patches_fe, criterion, optimizer, epochs=fe_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_MLAE_patches_fe['test_loss'])\n",
    "plt.plot(range(0, fe_epochs+1, fe_epochs//10), loss_MLAE_patches_fe['val_loss'])\n",
    "plt.legend(loss_MLAE_patches_fe.keys())\n",
    "\n",
    "net_MLAE_patches.cpu()\n",
    "del net_MLAE_patches\n",
    "\n",
    "net_MLAE_patches_fe.cpu()\n",
    "del net_MLAE_patches_fe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('SSL_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c3c12edae13c0508bae753e64eeaec91e16c05e32c8c48bac5bd7ee2e37cd7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
